# =============================================================================
# Tabi — Production Docker Compose
# =============================================================================
# Traffic flow:
#   Browser → Cloudflare (HTTPS/Full Strict) → Tunnel → app:8000
#
# Services:
#   cloudflared  — Cloudflare Tunnel agent (replaces Traefik reverse proxy)
#   app          — Laravel application (FrankenPHP + Octane on port 8000)
#   queue        — Laravel queue worker (processes background jobs e.g. emails)
#   pgsql        — PostgreSQL 15 database
#   gotenberg    — PDF generation
#
# Volumes:
#   pgsql-data   — PostgreSQL data, persists across restarts
#   app-storage  — Laravel storage dir, persists Passport OAuth keys and uploads
#
# SSL: Managed entirely by Cloudflare (Full Strict mode).
#      No certificates on the VPS. No open ports 80 or 443.
# =============================================================================

services:

  # ---------------------------------------------------------------------------
  # Cloudflare Tunnel
  # ---------------------------------------------------------------------------
  # Replaces Traefik as the ingress layer. Creates an outbound encrypted
  # connection to Cloudflare — no inbound ports needed on the VPS.
  # The tunnel is configured in Cloudflare Zero Trust → Networks → Tunnels.
  # Public hostname: tabitrack.com → backend: app:8000
  # Token is stored in .env as CLOUDFLARE_TUNNEL_TOKEN.
  # ---------------------------------------------------------------------------
  cloudflared:
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TUNNEL_TOKEN}
    networks:
      - internal

  # ---------------------------------------------------------------------------
  # Tabi Application
  # ---------------------------------------------------------------------------
  # Laravel app running on FrankenPHP + Octane (port 8000).
  # The app-storage volume persists Passport OAuth keys (oauth-private.key,
  # oauth-public.key) so they survive container restarts and image updates.
  # ---------------------------------------------------------------------------
  app:
    image: ghcr.io/mohamedyamanai/tabi:main
    restart: unless-stopped
    depends_on:
      pgsql:
        condition: service_healthy
    env_file: .env
    volumes:
      - app-storage:/var/www/html/storage
    networks:
      - internal

  # ---------------------------------------------------------------------------
  # Queue Worker
  # ---------------------------------------------------------------------------
  # Runs Laravel queue:work to process background jobs from the database queue.
  # Required for sending emails (e.g. organisation invitations via Resend).
  # Without this, queued jobs sit in the jobs table and are never processed.
  # Restarted automatically on each deployment via GitHub Actions.
  # ---------------------------------------------------------------------------
  queue:
    image: ghcr.io/mohamedyamanai/tabi:main
    restart: unless-stopped
    command: php artisan queue:work --sleep=3 --tries=3 --max-time=3600
    depends_on:
      pgsql:
        condition: service_healthy
    env_file: .env
    volumes:
      - app-storage:/var/www/html/storage
    networks:
      - internal

  # ---------------------------------------------------------------------------
  # PostgreSQL 15
  # ---------------------------------------------------------------------------
  # Primary database. Data is persisted in the pgsql-data Docker volume.
  # Credentials are loaded from .env (DB_DATABASE, DB_USERNAME, DB_PASSWORD).
  # ---------------------------------------------------------------------------
  pgsql:
    image: postgres:15
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_DATABASE}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - pgsql-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-q", "-d", "${DB_DATABASE}", "-U", "${DB_USERNAME}"]
      interval: 10s
      retries: 5
      timeout: 5s
    networks:
      - internal

  # ---------------------------------------------------------------------------
  # Gotenberg
  # ---------------------------------------------------------------------------
  # Headless PDF generation service used by the app for report exports.
  # Accessible internally at http://gotenberg:3000
  # ---------------------------------------------------------------------------
  gotenberg:
    image: gotenberg/gotenberg:8
    restart: unless-stopped
    networks:
      - internal

networks:
  # All services share one internal bridge network.
  # Nothing is reachable from outside except through the Cloudflare Tunnel.
  internal:
    driver: bridge

volumes:
  pgsql-data:
    driver: local
  app-storage:
    driver: local


# =============================================================================
# OLD LOCAL DEVELOPMENT CONFIG (Laravel Sail)
# =============================================================================
# The following was the original local development docker-compose config using
# Laravel Sail with Traefik as a local reverse proxy.
#
# It has been replaced by the production config above. Key differences:
#
#   - Traefik (local reverse proxy)  → replaced by Cloudflare Tunnel
#   - Minio (local S3 storage)       → replaced by Cloudflare R2
#   - Mailpit (local email catcher)  → replaced by Resend SMTP
#   - Laravel Sail image             → replaced by ghcr.io/mohamedyamanai/tabi:main
#   - Source code volume mounts      → removed (production runs from built image)
#
# Do not uncomment this section for production use.
# =============================================================================

# services:
#     laravel.test:
#         build:
#             context: ./docker/local/8.3
#             dockerfile: Dockerfile
#             args:
#                 WWWGROUP: '${WWWGROUP}'
#         image: sail-8.3/app
#         labels:
#             - "traefik.enable=true"
#             - "traefik.docker.network=${NETWORK_NAME}"
#             - "traefik.http.services.solidtime-dev.loadbalancer.server.port=80"
#             - "traefik.http.routers.solidtime-dev.rule=Host(`${NGINX_HOST_NAME}`)"
#             - "traefik.http.routers.solidtime-dev.entrypoints=web"
#             - "traefik.http.routers.solidtime-dev.service=solidtime-dev"
#             - "traefik.http.routers.solidtime-dev-https.rule=Host(`${NGINX_HOST_NAME}`)"
#             - "traefik.http.routers.solidtime-dev-https.service=solidtime-dev"
#             - "traefik.http.routers.solidtime-dev-https.entrypoints=websecure"
#             - "traefik.http.routers.solidtime-dev-https.tls=true"
#             # vite
#             - "traefik.http.services.solidtime-dev-vite.loadbalancer.server.port=5173"
#             - "traefik.http.routers.solidtime-dev-vite.rule=Host(`${VITE_HOST_NAME}`)"
#             - "traefik.http.routers.solidtime-dev-vite.service=solidtime-dev-vite"
#             - "traefik.http.routers.solidtime-dev-vite.entrypoints=web"
#         extra_hosts:
#             - "host.docker.internal:host-gateway"
#             - "storage.${NGINX_HOST_NAME}:${REVERSE_PROXY_IP:-10.100.100.10}"
#         environment:
#             XDG_CONFIG_HOME: /var/www/html/config
#             XDG_DATA_HOME: /var/www/html/data
#             WWWUSER: '${WWWUSER}'
#             LARAVEL_SAIL: 1
#             XDEBUG_MODE: '${SAIL_XDEBUG_MODE:-off}'
#             XDEBUG_CONFIG: '${SAIL_XDEBUG_CONFIG:-client_host=host.docker.internal}'
#             IGNITION_LOCAL_SITES_PATH: '${PWD}'
#             VITE_HOST_NAME: '${VITE_HOST_NAME}'
#         volumes:
#             - '.:/var/www/html'
#         networks:
#             - sail
#             - reverse-proxy
#         depends_on:
#             - pgsql
#
#     pgsql:
#         image: 'postgres:15'
#         ports:
#             - '${FORWARD_DB_PORT:-5432}:5432'
#         environment:
#             PGPASSWORD: '${DB_PASSWORD:-secret}'
#             POSTGRES_DB: '${DB_DATABASE}'
#             POSTGRES_USER: '${DB_USERNAME}'
#             POSTGRES_PASSWORD: '${DB_PASSWORD:-secret}'
#         volumes:
#             - 'sail-pgsql:/var/lib/postgresql/data'
#             - './docker/local/pgsql/create-testing-database.sql:/docker-entrypoint-initdb.d/10-create-testing-database.sql'
#         networks:
#             - sail
#         healthcheck:
#             test: [CMD, pg_isready, '-q', '-d', '${DB_DATABASE}', '-U', '${DB_USERNAME}']
#             retries: 3
#             timeout: 5s
#
#     pgsql_test:
#         image: 'postgres:15'
#         environment:
#             PGPASSWORD: '${DB_PASSWORD:-secret}'
#             POSTGRES_DB: '${DB_DATABASE}'
#             POSTGRES_USER: '${DB_USERNAME}'
#             POSTGRES_PASSWORD: '${DB_PASSWORD:-secret}'
#         volumes:
#             - 'sail-pgsql-test:/var/lib/postgresql/data'
#             - './docker/local/pgsql/create-testing-database.sql:/docker-entrypoint-initdb.d/10-create-testing-database.sql'
#         networks:
#             - sail
#         healthcheck:
#             test: [CMD, pg_isready, '-q', '-d', '${DB_DATABASE}', '-U', '${DB_USERNAME}']
#             retries: 3
#             timeout: 5s
#
#     mailpit:
#         # Local email catcher — replaced by Resend SMTP in production
#         image: 'axllent/mailpit:latest'
#         labels:
#             - "traefik.enable=true"
#             - "traefik.docker.network=${NETWORK_NAME}"
#             - "traefik.http.services.solidtime-dev-mailpit.loadbalancer.server.port=8025"
#             - "traefik.http.routers.solidtime-dev-mailpit.rule=Host(`mail.${NGINX_HOST_NAME}`)"
#             - "traefik.http.routers.solidtime-dev-mailpit.entrypoints=web"
#             - "traefik.http.routers.solidtime-dev-mailpit.service=solidtime-dev-mailpit"
#         networks:
#             - sail
#             - reverse-proxy
#
#     playwright:
#         image: mcr.microsoft.com/playwright:v1.58.1-jammy
#         command: ['npx', 'playwright', 'test', '--ui-port=8080', '--ui-host=0.0.0.0']
#         working_dir: /src
#         extra_hosts:
#             - "${NGINX_HOST_NAME}:${REVERSE_PROXY_IP:-10.100.100.10}"
#             - "${VITE_HOST_NAME}:${REVERSE_PROXY_IP:-10.100.100.10}"
#         networks:
#             - sail
#             - reverse-proxy
#         volumes:
#             - '.:/src'
#
#     minio:
#         # Local S3-compatible storage — replaced by Cloudflare R2 in production
#         image: 'minio/minio:latest'
#         environment:
#             MINIO_BROWSER_REDIRECT_URL: 'https://storage-management.${NGINX_HOST_NAME}'
#             MINIO_ROOT_USER: 'sail'
#             MINIO_ROOT_PASSWORD: 'password'
#         volumes:
#             - 'sail-minio:/data/minio'
#         networks:
#             - reverse-proxy
#             - sail
#         command: minio server /data/minio --console-address ":8900"
#         healthcheck:
#             test: [CMD, mc, ready, local]
#             interval: 5s
#             timeout: 5s
#             retries: 5
#
#     minio-create-bucket:
#         image: minio/mc:latest
#         depends_on:
#             - minio
#         environment:
#             S3_ACCESS_KEY_ID: ${S3_ACCESS_KEY_ID}
#             S3_SECRET_ACCESS_KEY: ${S3_SECRET_ACCESS_KEY}
#             S3_BUCKET: ${S3_BUCKET}
#             S3_ENDPOINT: ${S3_ENDPOINT}
#         volumes:
#             - './docker/local/minio:/etc/minio'
#         networks:
#             - sail
#             - reverse-proxy
#         entrypoint: /etc/minio/create_bucket.sh
#         extra_hosts:
#             - "storage.${NGINX_HOST_NAME}:${REVERSE_PROXY_IP:-10.100.100.10}"
#
#     gotenberg:
#         image: gotenberg/gotenberg:8
#         networks:
#             - sail
#         healthcheck:
#             test: ["CMD", "curl", "--silent", "--fail", "http://localhost:3000/health"]
#
# networks:
#     reverse-proxy:
#         name: "${NETWORK_NAME}"
#         external: true
#     sail:
#         driver: bridge
#
# volumes:
#     sail-pgsql:
#         driver: local
#     sail-pgsql-test:
#         driver: local
#     sail-minio:
#         driver: local